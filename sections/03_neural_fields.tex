\section{Neural Fields}
\begin{itemize}
	\item \textcolor{orange}{Field}: quantity defined for all spatial or temporal coordinates
	\item \textcolor{orange}{Neural Field}: field representation encoded by a neural network
\end{itemize}

\subsection{MLP as Data Structure}
\begin{itemize}
	\item MLP can represent complex signals (images, 3D shapes, etc)
	\item Sparse encoding of signal, shifts capacity where it needs it (based on optimization)
	\item Can be used for compression, denoising, super-resolution, etc.
	\item Often also referred to as Implicit Neural Representation (INR) or Coordinate-based MLP
\end{itemize}

\subsection{Implicit vs Explicit}
Implicit Neural Representation: Misleading since only the data structure is implicit not the function itself.
\begin{align}
	\text{Explicit function:} \quad & f(x) = y          \\
	\text{Implicit function:} \quad & x^2 + y^2 - 1 = 0
\end{align}

\textbf{Signed Distance Field (SDF)}
A signed distance field assigns to each point \(x \in \mathbb{R}^n\) a real value that
represents the distance to the closest surface, with the sign indicating whether the
point lies inside or outside the surface:
\[
	\mathrm{SDF}(x) =
	\begin{cases}
		< 0, & \text{inside surface},  \\
		= 0, & \text{on surface},      \\
		> 0, & \text{outside surface}.
	\end{cases}
\]

\textbf{Occupancy Field}
An occupancy field assigns to each point \(x \in \mathbb{R}^n\) a binary indication
of whether the point lies inside the surface:
\[
	\mathrm{Occ}(x) =
	\begin{cases}
		1, & \text{if } \mathrm{SDF}(x) \le 0, \\
		0, & \text{if } \mathrm{SDF}(x) > 0.
	\end{cases}
\]

\textbf{Key Difference}
\begin{itemize}
	\item \textbf{SDF:} continuous-valued; encodes signed distance from the surface.
	\item \textbf{Occupancy:} binary-valued; encodes only inside/outside.
\end{itemize}

\subsection{Overfitting vs. Generalization}
\begin{itemize}
	\item Overfitting as an artifact of neural fields: MLPs can memorize training data without generalizing.
	\item Overfitting as a debugging tool: helps to verify that the network architecture and training procedure are functioning correctly.
	\item Overfitting as a goal: to represent a specific signal or shape accurately.
\end{itemize}

\textbf{Overfitting Single Scene}
\begin{center}
	\includegraphics[width=\columnwidth]{images/overfitting_scene.jpeg}
	\label{fig:overfitting_scene}
\end{center}

\begin{itemize}
	\item Overfitting a single scene from multiple views
	\item Input set of images and their camera parameters
\end{itemize}

\textbf{Overfitting Multiple Scenes}
\begin{itemize}
	\item Each scene should have a unique description
	\item To prevent latent code bias in activations, either a positional encoding is required or a learned latent code (optimized during training)
	\item learned latent code: has semantic meaning: like parametrization of Radial Basis Functions (RBFs)
	\item Changing latent code allows interpolation between data
\end{itemize}

\begin{center}
	\includegraphics[width=\columnwidth]{images/overfitting_multiple_scenes.jpeg}
	\label{fig:overfitting_multiple_scenes}
\end{center}

\subsection{Inductive Bias}
\begin{itemize}
	\item Standard MLPs have a bias towards learning low-frequency signals (blurry).
	\item Also raw coordinates are biased towards absolute positions.
\end{itemize}

\textcolor{orange}{Shift invariance} is important to prevent bias in activations based on absolute coordinate values.
\begin{itemize}
	\item Positional encoding: Sinusoidal high-dimensional mapping of coordinates to keep the distance between coordinates meaningful  and preserve fine details
	\item SIREN Activations: sinusoidal activations to represent high-frequency functions
\end{itemize}
\href{https://arxiv.org/pdf/1806.08734}{On the Spectral Bias of Neural Networks, 2018}


\textbf{Positional Encoding}: \\
Sinusoidal / learned positional encodings allow:
\begin{itemize}
	\item[+] smooth distance representation,
	\item[+] easy extrapolation,
	\item[+] relative comparison (difference of phases encodes distance).
\end{itemize}

\begin{center}
	\includegraphics[width=\columnwidth]{images/positional_encoding.jpeg}
	\label{fig:positional_encoding}
\end{center}

\textbf{Activation Functions}
SIREN uses sinusoidal activations to fit to high-frequency functions.

\begin{center}
	\includegraphics[width=0.6\columnwidth]{images/SIREN.jpeg}
	\label{fig:SIREN}
\end{center}

\textbf{Remark:}
\begin{itemize}
	\item Combining positional encoding and sinusoidal activations is not necessary
	\item It can create a complex interference pattern that can make optimization extremely noisy
\end{itemize}

\subsection{Summary}
\begin{enumerate}
	\item Overfit an MLP
	\item Positional Encoding: prevent inductive bias from coordinates
	\item Activation Functions: non-linearities to represent high-frequency functions
\end{enumerate}

\vspace{0.3cm}
\hrule
\vspace{0.3cm}

\textbf{Comparison of Network Evolution}
\begin{itemize}
	\item MLP: fully connected layers, connect everything with everything
	\item CNN: local connections, weight sharing, translation equivariance
	\item Transformer: learn which connections are important
\end{itemize}